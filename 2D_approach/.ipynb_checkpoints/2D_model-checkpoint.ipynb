{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import scipy.spatial.distance\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "##\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathtub': 0,\n",
       " 'bed': 1,\n",
       " 'chair': 2,\n",
       " 'desk': 3,\n",
       " 'dresser': 4,\n",
       " 'monitor': 5,\n",
       " 'night_stand': 6,\n",
       " 'sofa': 7,\n",
       " 'table': 8,\n",
       " 'toilet': 9}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from path import Path\n",
    "\n",
    "path = Path(\"../Data/ModelNet10\")\n",
    "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
    "classes = {folder: i for i, folder in enumerate(folders)};\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_off(file):\n",
    "    if 'OFF' != file.readline().strip():\n",
    "        raise('Not a valid OFF header')\n",
    "    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n",
    "    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n",
    "    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample 3d points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointSampler(object):\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, int)\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def triangle_area(self, pt1, pt2, pt3):\n",
    "        side_a = np.linalg.norm(pt1 - pt2)\n",
    "        side_b = np.linalg.norm(pt2 - pt3)\n",
    "        side_c = np.linalg.norm(pt3 - pt1)\n",
    "        s = 0.5 * ( side_a + side_b + side_c)\n",
    "        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n",
    "\n",
    "    def sample_point(self, pt1, pt2, pt3):\n",
    "        # barycentric coordinates on a triangle\n",
    "        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n",
    "        s, t = sorted([random.random(), random.random()])\n",
    "        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n",
    "        return (f(0), f(1), f(2))\n",
    "        \n",
    "    \n",
    "    def __call__(self, mesh):\n",
    "        verts, faces = mesh\n",
    "        verts = np.array(verts)\n",
    "        areas = np.zeros((len(faces)))\n",
    "\n",
    "        for i in range(len(areas)):\n",
    "            areas[i] = (self.triangle_area(verts[faces[i][0]],\n",
    "                                           verts[faces[i][1]],\n",
    "                                           verts[faces[i][2]]))\n",
    "            \n",
    "        sampled_faces = (random.choices(faces, \n",
    "                                      weights=areas,\n",
    "                                      cum_weights=None,\n",
    "                                      k=self.output_size))\n",
    "        \n",
    "        sampled_points = np.zeros((self.output_size, 3))\n",
    "\n",
    "        for i in range(len(sampled_faces)):\n",
    "            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n",
    "                                                   verts[sampled_faces[i][1]],\n",
    "                                                   verts[sampled_faces[i][2]]))\n",
    "        \n",
    "        return sampled_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "        \n",
    "        norm_pointcloud = pointcloud - np.mean(pointcloud, axis=0) \n",
    "        norm_pointcloud /= np.max(np.linalg.norm(norm_pointcloud, axis=1))\n",
    "\n",
    "        return  norm_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take 2d photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makerotation(rx,ry,rz):\n",
    "    \"\"\"\n",
    "    Generate a rotation matrix    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rx,ry,rz : floats\n",
    "        Amount to rotate around x, y and z axes in degrees\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R : 2D numpy.array (dtype=float)\n",
    "        Rotation matrix of shape (3,3)\n",
    "    \"\"\"\n",
    "    rx = np.pi*rx/180.0\n",
    "    ry = np.pi*ry/180.0\n",
    "    rz = np.pi*rz/180.0\n",
    "\n",
    "    Rx = np.array([[1,0,0],[0,np.cos(rx),-np.sin(rx)],[0,np.sin(rx),np.cos(rx)]])\n",
    "    Ry = np.array([[np.cos(ry),0,-np.sin(ry)],[0,1,0],[np.sin(ry),0,np.cos(ry)]])\n",
    "    Rz = np.array([[np.cos(rz),-np.sin(rz),0],[np.sin(rz),np.cos(rz),0],[0,0,1]])\n",
    "    R = (Rz @ Ry @ Rx)\n",
    "    \n",
    "    return R \n",
    "\n",
    "class Camera:\n",
    "    \"\"\"\n",
    "    A simple data structure describing camera parameters \n",
    "    \n",
    "    The parameters describing the camera\n",
    "    cam.f : float   --- camera focal length (in units of pixels)\n",
    "    cam.c : 2x1 vector  --- offset of principle point\n",
    "    cam.R : 3x3 matrix --- camera rotation\n",
    "    cam.t : 3x1 vector --- camera translation \n",
    "\n",
    "    \n",
    "    \"\"\"    \n",
    "    def __init__(self,f,c,R,t):\n",
    "        self.f = f\n",
    "        self.c = c\n",
    "        self.R = R\n",
    "        self.t = t\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Camera : \\n f={self.f} \\n c={self.c.T} \\n R={self.R} \\n t = {self.t.T}'\n",
    "    \n",
    "    def project(self,pts3):\n",
    "        \"\"\"\n",
    "        Project the given 3D points in world coordinates into the specified camera    \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pts3 : 2D numpy.array (dtype=float)\n",
    "            Coordinates of N points stored in a array of shape (3,N)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pts2 : 2D numpy.array (dtype=float)\n",
    "            Image coordinates of N points stored in an array of shape (2,N)\n",
    "\n",
    "        \"\"\"\n",
    "        assert(pts3.shape[0]==3)\n",
    "\n",
    "        # get point location relative to camera\n",
    "        pcam = self.R.transpose() @ (pts3 - self.t)\n",
    "         \n",
    "        # project\n",
    "        p = self.f * (pcam / pcam[2,:])\n",
    "        \n",
    "        # offset principal point\n",
    "        pts2 = p[0:2,:] + self.c\n",
    "        \n",
    "        assert(pts2.shape[1]==pts3.shape[1])\n",
    "        assert(pts2.shape[0]==2)\n",
    "    \n",
    "        return pts2\n",
    " \n",
    "    def update_extrinsics(self,params):\n",
    "        \"\"\"\n",
    "        Given a vector of extrinsic parameters, update the camera\n",
    "        to use the provided parameters.\n",
    "  \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : 1D numpy.array (dtype=float)\n",
    "            Camera parameters we are optimizing over stored in a vector\n",
    "            params[0:2] are the rotation angles, params[2:5] are the translation\n",
    "\n",
    "        \"\"\"\n",
    "        self.R = makerotation(params[0],params[1],params[2])\n",
    "        self.t = np.array([[params[3]],[params[4]],[params[5]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1 = Camera(f=25,c=np.array([[16,16]]).T,t=np.array([[0,2,0]]).T, R=makerotation(90,0,0))\n",
    "cam2 = Camera(f=25,c=np.array([[16,16]]).T,t=np.array([[2,0,0]]).T, R=makerotation(0,90,0))\n",
    "cam3 = Camera(f=25,c=np.array([[16,16]]).T,t=np.array([[0,0,2]]).T, R=makerotation(180,0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if need to augment data... adding noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandRotation_z(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        theta = random.random() * 2. * math.pi\n",
    "        rot_matrix = np.array([[ math.cos(theta), -math.sin(theta),    0],\n",
    "                               [ math.sin(theta),  math.cos(theta),    0],\n",
    "                               [0,                             0,      1]])\n",
    "        \n",
    "        rot_pointcloud = rot_matrix.dot(pointcloud.T).T\n",
    "        return  rot_pointcloud\n",
    "    \n",
    "class RandomNoise(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        assert len(pointcloud.shape)==2\n",
    "\n",
    "        noise = np.random.normal(0, 0.02, (pointcloud.shape))\n",
    "    \n",
    "        noisy_pointcloud = pointcloud + noise\n",
    "        return  noisy_pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_data_point(object):\n",
    "    def __init__(self, cams):\n",
    "        self.cams = cams\n",
    "    \n",
    "    def __call__(self, pointcloud):\n",
    "        n = len(self.cams)\n",
    "        pts2 = np.zeros((n,32,32))\n",
    "        for i in range(n):\n",
    "            ind = self.cams[i].project(pointcloud.T).astype(int).T\n",
    "            for k,j in ind:\n",
    "                pts2[i,j,k] += 1\n",
    "\n",
    "        pts2 /= np.max(pts2)\n",
    "        return pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_3_view(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        pts2 = np.zeros((3,32,32))\n",
    "        pts2[0,:,:] = pointcloud[:,:2]\n",
    "        pts2[1,:,:] = pointcloud[:,1:]\n",
    "        pts2[2,:,:] = np.hstack((pointcloud[:,0], pointcloud[:,1]))\n",
    "\n",
    "        pts2 /= np.max(pts2)\n",
    "        return pts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, pointcloud):\n",
    "        return torch.from_numpy(pointcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam1 = Camera(f=25,c=np.array([[16,16]]).T,t=np.array([[0,2,0]]).T, R=makerotation(90,0,0))\n",
    "cam2 = Camera(f=25,c=np.array([[16,16]]).T,t=np.array([[2,0,0]]).T, R=makerotation(0,90,0))\n",
    "cam3 = Camera(f=25,c=np.array([[16,16]]).T,t=np.array([[0,0,2]]).T, R=makerotation(180,0,0))\n",
    "cams = [cam1,cam2,cam3]\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                    PointSampler(1024),\n",
    "                    Normalize(),\n",
    "                    RandRotation_z(),\n",
    "                    RandomNoise(),\n",
    "                    create_data_point(cams),\n",
    "                    ToTensor()\n",
    "                    ])\n",
    "\n",
    "transforms_3views = transforms.Compose([\n",
    "                    PointSampler(1024),\n",
    "                    Normalize(),\n",
    "                    RandRotation_z(),\n",
    "                    RandomNoise(),\n",
    "                    create_3_view(),\n",
    "                    ToTensor()\n",
    "                    ])\n",
    "\n",
    "def default_transforms():\n",
    "    return transforms.Compose([\n",
    "                    PointSampler(1024),\n",
    "                    Normalize(),\n",
    "                    create_data_point(cams),\n",
    "                    ToTensor()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudData(Dataset):\n",
    "    def __init__(self, root_dir, valid=False, folder=\"train\", transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [dir for dir in sorted(os.listdir(root_dir)) if os.path.isdir(root_dir/dir)]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform if not valid else default_transforms()\n",
    "        self.valid = valid\n",
    "        self.files = []\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir/Path(category)/folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith('.off'):\n",
    "                    sample = {}\n",
    "                    sample['pcd_path'] = new_dir/file\n",
    "                    sample['category'] = category\n",
    "                    self.files.append(sample)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __preproc__(self, file):\n",
    "        verts, faces = read_off(file)\n",
    "        if self.transforms:\n",
    "            pointcloud = self.transforms((verts, faces))\n",
    "        return pointcloud\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pcd_path = self.files[idx]['pcd_path']\n",
    "        category = self.files[idx]['category']\n",
    "        with open(pcd_path, 'r') as f:\n",
    "            pointcloud = self.__preproc__(f)\n",
    "        return {'pointcloud': pointcloud, \n",
    "                'category': self.classes[category]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs = 1, save = False):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, data in enumerate(train_loader):\n",
    "            x_var, y_var = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "\n",
    "            scores = model(x_var)\n",
    "            \n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % 10 == 0:\n",
    "                print('loss = %.4f' % (loss.data))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if save:\n",
    "            torch.save(model.state_dict(), \"save_\"+str(epoch)+\".pth\")\n",
    "    \n",
    "            \n",
    "def check_accuracy(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for i, data in enumerate(loader):\n",
    "        x_var, y = data['pointcloud'].to(device).float(), data['category']\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvOneView(nn.Module):\n",
    "    def __init__(self):\n",
    "        '''extracting features from single view'''\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,3,3)\n",
    "        self.conv2 = nn.Conv2d(3,64,3)\n",
    "        self.conv3 = nn.Conv2d(64,128,3)\n",
    "\n",
    "        self.fc1 = nn.Linear(86528,1024)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.fc3 = nn.Linear(256,64)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(3)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.bn4 = nn.BatchNorm1d(1024)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.bn6 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape == (bs,1,32,32)\n",
    "        \n",
    "        bs = input.size(0)\n",
    "        xb = nn.ReLU(inplace=True)(self.bn1(self.conv1(input)))\n",
    "        xb = nn.ReLU(inplace=True)(self.bn2(self.conv2(xb)))\n",
    "        xb = nn.ReLU(inplace=True)(self.bn3(self.conv3(xb)))\n",
    "        # pool = nn.MaxPool2d(2)(xb)\n",
    "        flat = nn.Flatten()(xb)\n",
    "        xb = nn.ReLU(inplace=True)(self.bn4(self.fc1(flat)))\n",
    "        # xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "        # xb = self.bn6(self.fc3(xb))\n",
    "\n",
    "        return xb\n",
    "\n",
    "\n",
    "class CombineMultiView(nn.Module):\n",
    "    '''extracting features from multi views'''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvOneView()\n",
    "\n",
    "    def forward(self, input):\n",
    "#         print(list(input[:,0,:,:][:,None,:,:].size()))\n",
    "        layer1 = self.conv1(input[:,0,:,:][:,None,:,:])\n",
    "        layer2 = self.conv1(input[:,1,:,:][:,None,:,:])\n",
    "        layer3 = self.conv1(input[:,2,:,:][:,None,:,:])\n",
    "        \n",
    "#         xb = nn.MaxPool1d(1)(torch.stack((layer1,layer2,layer3),2))\n",
    "        xb = nn.MaxPool1d(3)(torch.stack((layer1,layer2,layer3),2))\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        \n",
    "#         print(list(xb.size()))\n",
    "        \n",
    "        return output\n",
    "\n",
    "class MVNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.CombineMultiView = CombineMultiView()\n",
    "        self.fc1 = nn.Linear(3072, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb = self.CombineMultiView(input)\n",
    "        xb = nn.ReLU(inplace=True)(self.bn1(self.fc1(xb)))\n",
    "        xb = nn.ReLU(inplace=True)(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PointCloudData(Path(path), transform=train_transforms)\n",
    "valid_ds = PointCloudData(Path(path), valid=True, folder='test', transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MVNet(\n",
       "  (CombineMultiView): CombineMultiView(\n",
       "    (conv1): ConvOneView(\n",
       "      (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (fc1): Linear(in_features=86528, out_features=1024, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (logsoftmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointnet = MVNet()\n",
    "pointnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 2\n",
      "loss = 1.1746\n",
      "loss = 0.9882\n",
      "loss = 0.9467\n",
      "loss = 0.6342\n",
      "loss = 0.7401\n",
      "loss = 0.8540\n",
      "loss = 0.8664\n",
      "loss = 0.6687\n",
      "loss = 0.3555\n",
      "loss = 0.6290\n",
      "loss = 0.6760\n",
      "loss = 0.5506\n",
      "Starting epoch 2 / 2\n",
      "loss = 0.8112\n",
      "loss = 0.2116\n",
      "loss = 0.4016\n",
      "loss = 0.5771\n",
      "loss = 0.4924\n",
      "loss = 0.3902\n",
      "loss = 0.6925\n",
      "loss = 0.4240\n",
      "loss = 0.6352\n",
      "loss = 0.5200\n",
      "loss = 0.1642\n",
      "loss = 0.2697\n"
     ]
    }
   ],
   "source": [
    "train(pointnet, loss_fn, optimizer, num_epochs = 2, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(pointnet, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
