C:\Users\user\Anaconda3\python.exe "C:\Users\user\OneDrive - personalmicrosoftsoftware.uci.edu\2020Spring\CS175\175PointCloud\2D_approach\2d_model.py"
cuda:0
Starting epoch 1 / 50
loss = 1.2900
loss = 1.4229
loss = 1.6175
loss = 0.8779
loss = 1.2417
loss = 1.0777
loss = 1.5281
loss = 1.3952
loss = 0.6608
loss = 0.6440
loss = 0.3716
loss = 1.1071
Got 633 / 908 correct (69.71)
Starting epoch 2 / 50
loss = 0.4242
loss = 0.5560
loss = 0.4239
loss = 0.5926
loss = 0.3931
loss = 0.6094
loss = 0.4143
loss = 0.6235
loss = 0.7422
loss = 0.5978
loss = 0.6048
loss = 0.3806
Got 714 / 908 correct (78.63)
Starting epoch 3 / 50
loss = 0.5783
loss = 0.5889
loss = 0.3066
loss = 0.5840
loss = 0.5332
loss = 0.4147
loss = 0.4690
loss = 0.5502
loss = 0.4989
loss = 0.4713
loss = 0.7210
loss = 0.2937
Got 739 / 908 correct (81.39)
Starting epoch 4 / 50
loss = 0.4025
loss = 0.6047
loss = 0.3762
loss = 0.2794
loss = 0.8269
loss = 0.5941
loss = 0.2541
loss = 0.4039
loss = 0.4907
loss = 0.4262
loss = 0.9644
loss = 0.3343
Got 764 / 908 correct (84.14)
Starting epoch 5 / 50
loss = 0.5429
loss = 0.3716
loss = 0.3579
loss = 0.3328
loss = 0.4128
loss = 0.2933
loss = 0.2964
loss = 0.2176
loss = 0.5389
loss = 0.3390
loss = 0.5831
loss = 0.5252
Got 759 / 908 correct (83.59)
Starting epoch 6 / 50
loss = 0.4005
loss = 0.2346
loss = 0.9342
loss = 0.1827
loss = 0.8062
loss = 0.3637
loss = 0.1192
loss = 0.2812
loss = 0.4557
loss = 0.4321
loss = 0.2075
loss = 0.5868
Got 798 / 908 correct (87.89)
Starting epoch 7 / 50
loss = 0.6130
loss = 0.5766
loss = 0.1678
loss = 0.3873
loss = 0.4962
loss = 0.3760
loss = 0.2052
loss = 0.4524
loss = 0.2861
loss = 0.1827
loss = 0.4439
loss = 0.1935
Got 788 / 908 correct (86.78)
Starting epoch 8 / 50
loss = 0.2201
loss = 0.3548
loss = 0.1967
loss = 0.2188
loss = 0.2657
loss = 0.7893
loss = 0.2791
loss = 0.1464
loss = 0.3032
loss = 0.3102
loss = 0.2929
loss = 0.0945
Got 794 / 908 correct (87.44)
Starting epoch 9 / 50
loss = 0.3011
loss = 0.5228
loss = 0.1042
loss = 0.5668
loss = 0.4065
loss = 0.1830
loss = 0.3551
loss = 0.1038
loss = 0.2925
loss = 0.1866
loss = 0.2559
loss = 0.1901
Got 766 / 908 correct (84.36)
Starting epoch 10 / 50
loss = 0.1490
loss = 0.1240
loss = 0.2451
loss = 0.5459
loss = 0.3757
loss = 0.2669
loss = 0.3217
loss = 0.2543
loss = 0.1870
loss = 0.3568
loss = 0.3383
loss = 0.1297
Got 780 / 908 correct (85.90)
Epoch    10: reducing learning rate of group 0 to 1.0000e-02.
Starting epoch 11 / 50
loss = 0.5249
loss = 0.1701
loss = 0.2306
loss = 0.2263
loss = 0.2162
loss = 0.4219
loss = 0.0828
loss = 0.1010
loss = 0.1629
loss = 0.1209
loss = 0.0878
loss = 0.1058
Got 805 / 908 correct (88.66)
Starting epoch 12 / 50
loss = 0.2150
loss = 0.1636
loss = 0.0449
loss = 0.4093
loss = 0.2193
loss = 0.1631
loss = 0.3539
loss = 0.1541
loss = 0.2510
loss = 0.4755
loss = 0.1019
loss = 0.1918
Got 796 / 908 correct (87.67)
Starting epoch 13 / 50
loss = 0.1250
loss = 0.1234
loss = 0.1900
loss = 0.2781
loss = 0.1311
loss = 0.1858
loss = 0.0424
loss = 0.3062
loss = 0.2185
loss = 0.2022
loss = 0.1546
loss = 0.0958
Got 807 / 908 correct (88.88)
Starting epoch 14 / 50
loss = 0.1604
loss = 0.1827
loss = 0.0754
loss = 0.0999
loss = 0.0656
loss = 0.0948
loss = 0.1067
loss = 0.0924
loss = 0.1846
loss = 0.0425
loss = 0.3069
loss = 0.0467
Got 800 / 908 correct (88.11)
Starting epoch 15 / 50
loss = 0.2008
loss = 0.1354
loss = 0.1495
loss = 0.1004
loss = 0.1157
loss = 0.2272
loss = 0.2118
loss = 0.0582
loss = 0.1025
loss = 0.0863
loss = 0.1863
loss = 0.0726
Got 802 / 908 correct (88.33)
Starting epoch 16 / 50
loss = 0.2856
loss = 0.0697
loss = 0.2000
loss = 0.1870
loss = 0.0732
loss = 0.3018
loss = 0.1345
loss = 0.0173
loss = 0.0857
loss = 0.2846
loss = 0.1890
loss = 0.1085
Got 812 / 908 correct (89.43)
Starting epoch 17 / 50
loss = 0.1698
loss = 0.3185
loss = 0.0483
loss = 0.2269
loss = 0.1505
loss = 0.1205
loss = 0.1121
loss = 0.0326
loss = 0.1055
loss = 0.3346
loss = 0.0696
loss = 0.1405
Got 803 / 908 correct (88.44)
Starting epoch 18 / 50
loss = 0.2212
loss = 0.0345
loss = 0.1404
loss = 0.1187
loss = 0.1149
loss = 0.1786
loss = 0.0937
loss = 0.0465
loss = 0.1119
loss = 0.0976
loss = 0.3413
loss = 0.3544
Got 812 / 908 correct (89.43)
Starting epoch 19 / 50
loss = 0.3796
loss = 0.2980
loss = 0.3334
loss = 0.1515
loss = 0.1280
loss = 0.0750
loss = 0.1622
loss = 0.2923
loss = 0.0760
loss = 0.1127
loss = 0.0559
loss = 0.0668
Got 810 / 908 correct (89.21)
Starting epoch 20 / 50
loss = 0.0785
loss = 0.1397
loss = 0.0764
loss = 0.1621
loss = 0.3587
loss = 0.1967
loss = 0.0433
loss = 0.1933
loss = 0.1066
loss = 0.1500
loss = 0.1710
loss = 0.1409
Got 821 / 908 correct (90.42)
Starting epoch 21 / 50
loss = 0.3467
loss = 0.0924
loss = 0.0877
loss = 0.1289
loss = 0.0983
loss = 0.4767
loss = 0.1693
loss = 0.0831
loss = 0.3616
loss = 0.1347
loss = 0.2652
loss = 0.1826
Got 810 / 908 correct (89.21)
Starting epoch 22 / 50
loss = 0.0702
loss = 0.2270
loss = 0.0680
loss = 0.1088
loss = 0.2454
loss = 0.1937
loss = 0.1895
loss = 0.0896
loss = 0.1022
loss = 0.3380
loss = 0.0212
loss = 0.0337
Got 817 / 908 correct (89.98)
Starting epoch 23 / 50
loss = 0.2584
loss = 0.2903
loss = 0.2527
loss = 0.2019
loss = 0.1387
loss = 0.1221
loss = 0.1112
loss = 0.0421
loss = 0.1508
loss = 0.0582
loss = 0.0741
loss = 0.4884
Got 812 / 908 correct (89.43)
Starting epoch 24 / 50
loss = 0.0431
loss = 0.1809
loss = 0.0472
loss = 0.1069
loss = 0.2272
loss = 0.0610
loss = 0.0661
loss = 0.0646
loss = 0.1179
loss = 0.1549
loss = 0.0994
loss = 0.1563
Got 814 / 908 correct (89.65)
Epoch    24: reducing learning rate of group 0 to 1.0000e-03.
Starting epoch 25 / 50
loss = 0.1605
loss = 0.0836
loss = 0.0817
loss = 0.2001
loss = 0.1967
loss = 0.0921
loss = 0.1696
loss = 0.1392
loss = 0.0935
loss = 0.1319
loss = 0.0154
loss = 0.1161
Got 812 / 908 correct (89.43)
Starting epoch 26 / 50
loss = 0.0963
loss = 0.2707
loss = 0.1922
loss = 0.1277
loss = 0.1405
loss = 0.1453
loss = 0.0618
loss = 0.0394
loss = 0.0898
loss = 0.2266
loss = 0.1360
loss = 0.2052
Got 817 / 908 correct (89.98)
Starting epoch 27 / 50
loss = 0.1819
loss = 0.0617
loss = 0.3193
loss = 0.1388
loss = 0.0821
loss = 0.0851
loss = 0.1696
loss = 0.1571
loss = 0.1559
loss = 0.1700
loss = 0.0503
loss = 0.1491
Got 819 / 908 correct (90.20)
Starting epoch 28 / 50
loss = 0.0754
loss = 0.0572
loss = 0.2191
loss = 0.4683
loss = 0.1815
loss = 0.1507
loss = 0.1225
loss = 0.0769
loss = 0.3086
loss = 0.1176
loss = 0.0952
loss = 0.1329
Got 811 / 908 correct (89.32)
Epoch    28: reducing learning rate of group 0 to 1.0000e-04.
Starting epoch 29 / 50
loss = 0.3555
loss = 0.1474
loss = 0.0184
loss = 0.2471
loss = 0.4734
loss = 0.0507
loss = 0.0619
loss = 0.1967
loss = 0.0735
loss = 0.2782
loss = 0.1433
loss = 0.2734
Got 810 / 908 correct (89.21)
Starting epoch 30 / 50
loss = 0.1493
loss = 0.2054
loss = 0.1259
loss = 0.2386
loss = 0.1568
loss = 0.1366
loss = 0.2750
loss = 0.0521
loss = 0.0101
loss = 0.1524
loss = 0.0689
loss = 0.1183
Got 813 / 908 correct (89.54)
Starting epoch 31 / 50
loss = 0.0454
loss = 0.0274
loss = 0.0098
loss = 0.3223
loss = 0.0214
loss = 0.0315
loss = 0.3116
loss = 0.0784
loss = 0.1071
loss = 0.3688
loss = 0.0867
loss = 0.1464
Got 817 / 908 correct (89.98)
Starting epoch 32 / 50
loss = 0.1198
loss = 0.1524
loss = 0.0409
loss = 0.0882
loss = 0.1320
loss = 0.1076
loss = 0.0512
loss = 0.0963
loss = 0.1127
loss = 0.1934
loss = 0.1672
loss = 0.1182
Got 818 / 908 correct (90.09)
Epoch    32: reducing learning rate of group 0 to 1.0000e-05.
Starting epoch 33 / 50
loss = 0.0939
loss = 0.0296
loss = 0.1807
loss = 0.0326
loss = 0.0116
loss = 0.2119
loss = 0.1278
loss = 0.0721
loss = 0.2462
loss = 0.0410
loss = 0.1336
loss = 0.1414
Got 822 / 908 correct (90.53)
Starting epoch 34 / 50
loss = 0.2958
loss = 0.0769
loss = 0.0981
loss = 0.1337
loss = 0.1330
loss = 0.2289
loss = 0.0319
loss = 0.1791
loss = 0.2781
loss = 0.0504
loss = 0.0630
loss = 0.1199
Got 809 / 908 correct (89.10)
Starting epoch 35 / 50
loss = 0.1870
loss = 0.2097
loss = 0.2228
loss = 0.1279
loss = 0.0596
loss = 0.0614
loss = 0.0808
loss = 0.1011
loss = 0.0407
loss = 0.0906
loss = 0.2520
loss = 0.1759
Got 814 / 908 correct (89.65)
Starting epoch 36 / 50
loss = 0.0904
loss = 0.0641
loss = 0.0750
loss = 0.2111
loss = 0.0468
loss = 0.1213
loss = 0.3080
loss = 0.0820
loss = 0.0173
loss = 0.1365
loss = 0.1536
loss = 0.1409
Got 816 / 908 correct (89.87)
Starting epoch 37 / 50
loss = 0.0542
loss = 0.2856
loss = 0.3119
loss = 0.1694
loss = 0.1741
loss = 0.0691
loss = 0.2662
loss = 0.0745
loss = 0.1600
loss = 0.1417
loss = 0.2651
loss = 0.0910
Got 819 / 908 correct (90.20)
Epoch    37: reducing learning rate of group 0 to 1.0000e-06.
Starting epoch 38 / 50
