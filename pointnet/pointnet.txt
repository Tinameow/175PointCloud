C:\Users\user\Anaconda3\python.exe "C:/Users/user/OneDrive - personalmicrosoftsoftware.uci.edu/2020Spring/CS175/175PointCloud/pointnet/run_pointnet.py"
cuda:0
[Epoch: 1, Batch:   10 /  125], loss: 1.881
[Epoch: 1, Batch:   20 /  125], loss: 1.712
[Epoch: 1, Batch:   30 /  125], loss: 1.431
[Epoch: 1, Batch:   40 /  125], loss: 1.232
[Epoch: 1, Batch:   50 /  125], loss: 1.288
[Epoch: 1, Batch:   60 /  125], loss: 1.111
[Epoch: 1, Batch:   70 /  125], loss: 1.044
[Epoch: 1, Batch:   80 /  125], loss: 0.908
[Epoch: 1, Batch:   90 /  125], loss: 0.871
[Epoch: 1, Batch:  100 /  125], loss: 0.891
[Epoch: 1, Batch:  110 /  125], loss: 0.851
[Epoch: 1, Batch:  120 /  125], loss: 0.809
Valid accuracy: 63 %
[Epoch: 2, Batch:   10 /  125], loss: 0.832
[Epoch: 2, Batch:   20 /  125], loss: 0.845
[Epoch: 2, Batch:   30 /  125], loss: 0.799
[Epoch: 2, Batch:   40 /  125], loss: 0.749
[Epoch: 2, Batch:   50 /  125], loss: 0.686
[Epoch: 2, Batch:   60 /  125], loss: 0.724
[Epoch: 2, Batch:   70 /  125], loss: 0.810
[Epoch: 2, Batch:   80 /  125], loss: 0.862
[Epoch: 2, Batch:   90 /  125], loss: 0.663
[Epoch: 2, Batch:  100 /  125], loss: 0.783
[Epoch: 2, Batch:  110 /  125], loss: 0.815
[Epoch: 2, Batch:  120 /  125], loss: 0.732
Valid accuracy: 71 %
[Epoch: 3, Batch:   10 /  125], loss: 0.692
[Epoch: 3, Batch:   20 /  125], loss: 0.683
[Epoch: 3, Batch:   30 /  125], loss: 0.728
[Epoch: 3, Batch:   40 /  125], loss: 0.672
[Epoch: 3, Batch:   50 /  125], loss: 0.645
[Epoch: 3, Batch:   60 /  125], loss: 0.617
[Epoch: 3, Batch:   70 /  125], loss: 0.568
[Epoch: 3, Batch:   80 /  125], loss: 0.645
[Epoch: 3, Batch:   90 /  125], loss: 0.554
[Epoch: 3, Batch:  100 /  125], loss: 0.648
[Epoch: 3, Batch:  110 /  125], loss: 0.662
[Epoch: 3, Batch:  120 /  125], loss: 0.568
Valid accuracy: 78 %
[Epoch: 4, Batch:   10 /  125], loss: 0.567
[Epoch: 4, Batch:   20 /  125], loss: 0.533
[Epoch: 4, Batch:   30 /  125], loss: 0.597
[Epoch: 4, Batch:   40 /  125], loss: 0.619
[Epoch: 4, Batch:   50 /  125], loss: 0.579
[Epoch: 4, Batch:   60 /  125], loss: 0.704
[Epoch: 4, Batch:   70 /  125], loss: 0.642
[Epoch: 4, Batch:   80 /  125], loss: 0.609
[Epoch: 4, Batch:   90 /  125], loss: 0.577
[Epoch: 4, Batch:  100 /  125], loss: 0.542
[Epoch: 4, Batch:  110 /  125], loss: 0.527
[Epoch: 4, Batch:  120 /  125], loss: 0.565
Valid accuracy: 76 %
[Epoch: 5, Batch:   10 /  125], loss: 0.617
[Epoch: 5, Batch:   20 /  125], loss: 0.502
[Epoch: 5, Batch:   30 /  125], loss: 0.573
[Epoch: 5, Batch:   40 /  125], loss: 0.581
[Epoch: 5, Batch:   50 /  125], loss: 0.575
[Epoch: 5, Batch:   60 /  125], loss: 0.518
[Epoch: 5, Batch:   70 /  125], loss: 0.519
[Epoch: 5, Batch:   80 /  125], loss: 0.446
[Epoch: 5, Batch:   90 /  125], loss: 0.510
[Epoch: 5, Batch:  100 /  125], loss: 0.456
[Epoch: 5, Batch:  110 /  125], loss: 0.461
[Epoch: 5, Batch:  120 /  125], loss: 0.554
Valid accuracy: 63 %
[Epoch: 6, Batch:   10 /  125], loss: 0.666
[Epoch: 6, Batch:   20 /  125], loss: 0.621
[Epoch: 6, Batch:   30 /  125], loss: 0.584
[Epoch: 6, Batch:   40 /  125], loss: 0.482
[Epoch: 6, Batch:   50 /  125], loss: 0.501
[Epoch: 6, Batch:   60 /  125], loss: 0.474
[Epoch: 6, Batch:   70 /  125], loss: 0.449
[Epoch: 6, Batch:   80 /  125], loss: 0.534
[Epoch: 6, Batch:   90 /  125], loss: 0.481
[Epoch: 6, Batch:  100 /  125], loss: 0.447
[Epoch: 6, Batch:  110 /  125], loss: 0.411
[Epoch: 6, Batch:  120 /  125], loss: 0.552
Valid accuracy: 78 %
[Epoch: 7, Batch:   10 /  125], loss: 0.464
[Epoch: 7, Batch:   20 /  125], loss: 0.450
[Epoch: 7, Batch:   30 /  125], loss: 0.491
[Epoch: 7, Batch:   40 /  125], loss: 0.468
[Epoch: 7, Batch:   50 /  125], loss: 0.444
[Epoch: 7, Batch:   60 /  125], loss: 0.487
[Epoch: 7, Batch:   70 /  125], loss: 0.466
[Epoch: 7, Batch:   80 /  125], loss: 0.421
[Epoch: 7, Batch:   90 /  125], loss: 0.501
[Epoch: 7, Batch:  100 /  125], loss: 0.530
[Epoch: 7, Batch:  110 /  125], loss: 0.448
[Epoch: 7, Batch:  120 /  125], loss: 0.560
Valid accuracy: 76 %
[Epoch: 8, Batch:   10 /  125], loss: 0.613
[Epoch: 8, Batch:   20 /  125], loss: 0.501
[Epoch: 8, Batch:   30 /  125], loss: 0.382
[Epoch: 8, Batch:   40 /  125], loss: 0.503
[Epoch: 8, Batch:   50 /  125], loss: 0.476
[Epoch: 8, Batch:   60 /  125], loss: 0.350
[Epoch: 8, Batch:   70 /  125], loss: 0.451
[Epoch: 8, Batch:   80 /  125], loss: 0.394
[Epoch: 8, Batch:   90 /  125], loss: 0.348
[Epoch: 8, Batch:  100 /  125], loss: 0.381
[Epoch: 8, Batch:  110 /  125], loss: 0.438
[Epoch: 8, Batch:  120 /  125], loss: 0.466
Valid accuracy: 73 %
[Epoch: 9, Batch:   10 /  125], loss: 0.483
[Epoch: 9, Batch:   20 /  125], loss: 0.570
[Epoch: 9, Batch:   30 /  125], loss: 0.412
[Epoch: 9, Batch:   40 /  125], loss: 0.426
[Epoch: 9, Batch:   50 /  125], loss: 0.444
[Epoch: 9, Batch:   60 /  125], loss: 0.418
[Epoch: 9, Batch:   70 /  125], loss: 0.511
[Epoch: 9, Batch:   80 /  125], loss: 0.396
[Epoch: 9, Batch:   90 /  125], loss: 0.474
[Epoch: 9, Batch:  100 /  125], loss: 0.339
[Epoch: 9, Batch:  110 /  125], loss: 0.517
[Epoch: 9, Batch:  120 /  125], loss: 0.406
Valid accuracy: 78 %
[Epoch: 10, Batch:   10 /  125], loss: 0.472
[Epoch: 10, Batch:   20 /  125], loss: 0.405
[Epoch: 10, Batch:   30 /  125], loss: 0.378
[Epoch: 10, Batch:   40 /  125], loss: 0.364
[Epoch: 10, Batch:   50 /  125], loss: 0.348
[Epoch: 10, Batch:   60 /  125], loss: 0.443
[Epoch: 10, Batch:   70 /  125], loss: 0.429
[Epoch: 10, Batch:   80 /  125], loss: 0.411
[Epoch: 10, Batch:   90 /  125], loss: 0.392
[Epoch: 10, Batch:  100 /  125], loss: 0.349
[Epoch: 10, Batch:  110 /  125], loss: 0.292
[Epoch: 10, Batch:  120 /  125], loss: 0.339
Valid accuracy: 82 %
[Epoch: 11, Batch:   10 /  125], loss: 0.443
[Epoch: 11, Batch:   20 /  125], loss: 0.525
[Epoch: 11, Batch:   30 /  125], loss: 0.540
[Epoch: 11, Batch:   40 /  125], loss: 0.341
[Epoch: 11, Batch:   50 /  125], loss: 0.438
[Epoch: 11, Batch:   60 /  125], loss: 0.312
[Epoch: 11, Batch:   70 /  125], loss: 0.408
[Epoch: 11, Batch:   80 /  125], loss: 0.331
[Epoch: 11, Batch:   90 /  125], loss: 0.360
[Epoch: 11, Batch:  100 /  125], loss: 0.451
[Epoch: 11, Batch:  110 /  125], loss: 0.445
[Epoch: 11, Batch:  120 /  125], loss: 0.411
Valid accuracy: 80 %
[Epoch: 12, Batch:   10 /  125], loss: 0.445
[Epoch: 12, Batch:   20 /  125], loss: 0.564
[Epoch: 12, Batch:   30 /  125], loss: 0.358
[Epoch: 12, Batch:   40 /  125], loss: 0.461
[Epoch: 12, Batch:   50 /  125], loss: 0.365
[Epoch: 12, Batch:   60 /  125], loss: 0.425
[Epoch: 12, Batch:   70 /  125], loss: 0.342
[Epoch: 12, Batch:   80 /  125], loss: 0.357
[Epoch: 12, Batch:   90 /  125], loss: 0.362
[Epoch: 12, Batch:  100 /  125], loss: 0.396
[Epoch: 12, Batch:  110 /  125], loss: 0.383
[Epoch: 12, Batch:  120 /  125], loss: 0.455
Valid accuracy: 84 %
[Epoch: 13, Batch:   10 /  125], loss: 0.421
[Epoch: 13, Batch:   20 /  125], loss: 0.373
[Epoch: 13, Batch:   30 /  125], loss: 0.432
[Epoch: 13, Batch:   40 /  125], loss: 0.325
[Epoch: 13, Batch:   50 /  125], loss: 0.353
[Epoch: 13, Batch:   60 /  125], loss: 0.344
[Epoch: 13, Batch:   70 /  125], loss: 0.321
[Epoch: 13, Batch:   80 /  125], loss: 0.328
[Epoch: 13, Batch:   90 /  125], loss: 0.350
[Epoch: 13, Batch:  100 /  125], loss: 0.364
[Epoch: 13, Batch:  110 /  125], loss: 0.320
[Epoch: 13, Batch:  120 /  125], loss: 0.342
Valid accuracy: 76 %
[Epoch: 14, Batch:   10 /  125], loss: 0.306
[Epoch: 14, Batch:   20 /  125], loss: 0.361
[Epoch: 14, Batch:   30 /  125], loss: 0.358
[Epoch: 14, Batch:   40 /  125], loss: 0.388
[Epoch: 14, Batch:   50 /  125], loss: 0.343
[Epoch: 14, Batch:   60 /  125], loss: 0.395
[Epoch: 14, Batch:   70 /  125], loss: 0.416
[Epoch: 14, Batch:   80 /  125], loss: 0.300
[Epoch: 14, Batch:   90 /  125], loss: 0.329
[Epoch: 14, Batch:  100 /  125], loss: 0.444
[Epoch: 14, Batch:  110 /  125], loss: 0.360
[Epoch: 14, Batch:  120 /  125], loss: 0.321
Valid accuracy: 84 %
[Epoch: 15, Batch:   10 /  125], loss: 0.299
[Epoch: 15, Batch:   20 /  125], loss: 0.296
[Epoch: 15, Batch:   30 /  125], loss: 0.407
[Epoch: 15, Batch:   40 /  125], loss: 0.400
[Epoch: 15, Batch:   50 /  125], loss: 0.393
[Epoch: 15, Batch:   60 /  125], loss: 0.365
[Epoch: 15, Batch:   70 /  125], loss: 0.258
[Epoch: 15, Batch:   80 /  125], loss: 0.292
[Epoch: 15, Batch:   90 /  125], loss: 0.290
[Epoch: 15, Batch:  100 /  125], loss: 0.314
[Epoch: 15, Batch:  110 /  125], loss: 0.382
[Epoch: 15, Batch:  120 /  125], loss: 0.310
Valid accuracy: 79 %

Process finished with exit code 0

[Epoch: 1, Batch:   10 /  125], loss: 0.330
[Epoch: 1, Batch:   20 /  125], loss: 0.363
[Epoch: 1, Batch:   30 /  125], loss: 0.255
[Epoch: 1, Batch:   40 /  125], loss: 0.339
[Epoch: 1, Batch:   50 /  125], loss: 0.277
[Epoch: 1, Batch:   60 /  125], loss: 0.274
[Epoch: 1, Batch:   70 /  125], loss: 0.265
[Epoch: 1, Batch:   80 /  125], loss: 0.291
[Epoch: 1, Batch:   90 /  125], loss: 0.242
[Epoch: 1, Batch:  100 /  125], loss: 0.271
[Epoch: 1, Batch:  110 /  125], loss: 0.271
[Epoch: 1, Batch:  120 /  125], loss: 0.311
Valid accuracy: 87 %
[Epoch: 2, Batch:   10 /  125], loss: 0.318
[Epoch: 2, Batch:   20 /  125], loss: 0.171
[Epoch: 2, Batch:   30 /  125], loss: 0.283
[Epoch: 2, Batch:   40 /  125], loss: 0.267
[Epoch: 2, Batch:   50 /  125], loss: 0.241
[Epoch: 2, Batch:   60 /  125], loss: 0.260
[Epoch: 2, Batch:   70 /  125], loss: 0.290
[Epoch: 2, Batch:   80 /  125], loss: 0.224
[Epoch: 2, Batch:   90 /  125], loss: 0.267
[Epoch: 2, Batch:  100 /  125], loss: 0.234
[Epoch: 2, Batch:  110 /  125], loss: 0.299
[Epoch: 2, Batch:  120 /  125], loss: 0.228
Valid accuracy: 87 %
[Epoch: 3, Batch:   10 /  125], loss: 0.259
[Epoch: 3, Batch:   20 /  125], loss: 0.237
[Epoch: 3, Batch:   30 /  125], loss: 0.293
[Epoch: 3, Batch:   40 /  125], loss: 0.217
[Epoch: 3, Batch:   50 /  125], loss: 0.237
[Epoch: 3, Batch:   60 /  125], loss: 0.214
[Epoch: 3, Batch:   70 /  125], loss: 0.229
[Epoch: 3, Batch:   80 /  125], loss: 0.250
[Epoch: 3, Batch:   90 /  125], loss: 0.215
[Epoch: 3, Batch:  100 /  125], loss: 0.293
[Epoch: 3, Batch:  110 /  125], loss: 0.218
[Epoch: 3, Batch:  120 /  125], loss: 0.266
Valid accuracy: 87 %
[Epoch: 4, Batch:   10 /  125], loss: 0.215
[Epoch: 4, Batch:   20 /  125], loss: 0.195
[Epoch: 4, Batch:   30 /  125], loss: 0.306
[Epoch: 4, Batch:   40 /  125], loss: 0.231
[Epoch: 4, Batch:   50 /  125], loss: 0.227
[Epoch: 4, Batch:   60 /  125], loss: 0.263
[Epoch: 4, Batch:   70 /  125], loss: 0.281
[Epoch: 4, Batch:   80 /  125], loss: 0.292
[Epoch: 4, Batch:   90 /  125], loss: 0.247
[Epoch: 4, Batch:  100 /  125], loss: 0.248
[Epoch: 4, Batch:  110 /  125], loss: 0.257
[Epoch: 4, Batch:  120 /  125], loss: 0.175
Valid accuracy: 88 %
[Epoch: 5, Batch:   10 /  125], loss: 0.252
[Epoch: 5, Batch:   20 /  125], loss: 0.248
[Epoch: 5, Batch:   30 /  125], loss: 0.262
[Epoch: 5, Batch:   40 /  125], loss: 0.257
[Epoch: 5, Batch:   50 /  125], loss: 0.270
[Epoch: 5, Batch:   60 /  125], loss: 0.185
[Epoch: 5, Batch:   70 /  125], loss: 0.275
[Epoch: 5, Batch:   80 /  125], loss: 0.281
[Epoch: 5, Batch:   90 /  125], loss: 0.253
[Epoch: 5, Batch:  100 /  125], loss: 0.256
[Epoch: 5, Batch:  110 /  125], loss: 0.200
[Epoch: 5, Batch:  120 /  125], loss: 0.223
Valid accuracy: 87 %

C:\Users\user\Anaconda3\python.exe "C:/Users/user/OneDrive - personalmicrosoftsoftware.uci.edu/2020Spring/CS175/175PointCloud/pointnet/run_pointnet.py"
cuda:0
[Epoch: 1, Batch:   10 /  125], loss: 0.222
[Epoch: 1, Batch:   20 /  125], loss: 0.308
[Epoch: 1, Batch:   30 /  125], loss: 0.281
[Epoch: 1, Batch:   40 /  125], loss: 0.220
[Epoch: 1, Batch:   50 /  125], loss: 0.225
[Epoch: 1, Batch:   60 /  125], loss: 0.247
[Epoch: 1, Batch:   70 /  125], loss: 0.154
[Epoch: 1, Batch:   80 /  125], loss: 0.189
[Epoch: 1, Batch:   90 /  125], loss: 0.220
[Epoch: 1, Batch:  100 /  125], loss: 0.258
[Epoch: 1, Batch:  110 /  125], loss: 0.254
[Epoch: 1, Batch:  120 /  125], loss: 0.232
Valid accuracy: 87 %
[Epoch: 2, Batch:   10 /  125], loss: 0.216
[Epoch: 2, Batch:   20 /  125], loss: 0.201
[Epoch: 2, Batch:   30 /  125], loss: 0.196
[Epoch: 2, Batch:   40 /  125], loss: 0.203
[Epoch: 2, Batch:   50 /  125], loss: 0.274
[Epoch: 2, Batch:   60 /  125], loss: 0.185
[Epoch: 2, Batch:   70 /  125], loss: 0.190
[Epoch: 2, Batch:   80 /  125], loss: 0.235
[Epoch: 2, Batch:   90 /  125], loss: 0.246
[Epoch: 2, Batch:  100 /  125], loss: 0.251
[Epoch: 2, Batch:  110 /  125], loss: 0.247
[Epoch: 2, Batch:  120 /  125], loss: 0.282
Valid accuracy: 88 %
[Epoch: 3, Batch:   10 /  125], loss: 0.221
[Epoch: 3, Batch:   20 /  125], loss: 0.207
[Epoch: 3, Batch:   30 /  125], loss: 0.257
[Epoch: 3, Batch:   40 /  125], loss: 0.191
[Epoch: 3, Batch:   50 /  125], loss: 0.263
[Epoch: 3, Batch:   60 /  125], loss: 0.304
[Epoch: 3, Batch:   70 /  125], loss: 0.266
[Epoch: 3, Batch:   80 /  125], loss: 0.214
[Epoch: 3, Batch:   90 /  125], loss: 0.156
[Epoch: 3, Batch:  100 /  125], loss: 0.255
[Epoch: 3, Batch:  110 /  125], loss: 0.256
[Epoch: 3, Batch:  120 /  125], loss: 0.217
Valid accuracy: 88 %
[Epoch: 4, Batch:   10 /  125], loss: 0.185
[Epoch: 4, Batch:   20 /  125], loss: 0.179
[Epoch: 4, Batch:   30 /  125], loss: 0.216
[Epoch: 4, Batch:   40 /  125], loss: 0.273
[Epoch: 4, Batch:   50 /  125], loss: 0.284
[Epoch: 4, Batch:   60 /  125], loss: 0.183
[Epoch: 4, Batch:   70 /  125], loss: 0.225
[Epoch: 4, Batch:   80 /  125], loss: 0.239
[Epoch: 4, Batch:   90 /  125], loss: 0.253
[Epoch: 4, Batch:  100 /  125], loss: 0.249
[Epoch: 4, Batch:  110 /  125], loss: 0.179
[Epoch: 4, Batch:  120 /  125], loss: 0.191
Valid accuracy: 88 %
[Epoch: 5, Batch:   10 /  125], loss: 0.270
[Epoch: 5, Batch:   20 /  125], loss: 0.216
[Epoch: 5, Batch:   30 /  125], loss: 0.197
[Epoch: 5, Batch:   40 /  125], loss: 0.254
[Epoch: 5, Batch:   50 /  125], loss: 0.210
[Epoch: 5, Batch:   60 /  125], loss: 0.145
[Epoch: 5, Batch:   70 /  125], loss: 0.177
[Epoch: 5, Batch:   80 /  125], loss: 0.218
[Epoch: 5, Batch:   90 /  125], loss: 0.219
[Epoch: 5, Batch:  100 /  125], loss: 0.251
[Epoch: 5, Batch:  110 /  125], loss: 0.255
[Epoch: 5, Batch:  120 /  125], loss: 0.200
Valid accuracy: 87 %
[Epoch: 6, Batch:   10 /  125], loss: 0.182
[Epoch: 6, Batch:   20 /  125], loss: 0.190
[Epoch: 6, Batch:   30 /  125], loss: 0.202
[Epoch: 6, Batch:   40 /  125], loss: 0.235
[Epoch: 6, Batch:   50 /  125], loss: 0.249
[Epoch: 6, Batch:   60 /  125], loss: 0.230
[Epoch: 6, Batch:   70 /  125], loss: 0.281
[Epoch: 6, Batch:   80 /  125], loss: 0.213
[Epoch: 6, Batch:   90 /  125], loss: 0.306
[Epoch: 6, Batch:  100 /  125], loss: 0.185
[Epoch: 6, Batch:  110 /  125], loss: 0.280
[Epoch: 6, Batch:  120 /  125], loss: 0.251
Valid accuracy: 88 %
[Epoch: 7, Batch:   10 /  125], loss: 0.263
[Epoch: 7, Batch:   20 /  125], loss: 0.187
[Epoch: 7, Batch:   30 /  125], loss: 0.261
[Epoch: 7, Batch:   40 /  125], loss: 0.252
[Epoch: 7, Batch:   50 /  125], loss: 0.167
[Epoch: 7, Batch:   60 /  125], loss: 0.240
[Epoch: 7, Batch:   70 /  125], loss: 0.193
[Epoch: 7, Batch:   80 /  125], loss: 0.254
[Epoch: 7, Batch:   90 /  125], loss: 0.236
[Epoch: 7, Batch:  100 /  125], loss: 0.225
[Epoch: 7, Batch:  110 /  125], loss: 0.206
[Epoch: 7, Batch:  120 /  125], loss: 0.183
Valid accuracy: 87 %
[Epoch: 8, Batch:   10 /  125], loss: 0.192
[Epoch: 8, Batch:   20 /  125], loss: 0.242
[Epoch: 8, Batch:   30 /  125], loss: 0.180
[Epoch: 8, Batch:   40 /  125], loss: 0.189
[Epoch: 8, Batch:   50 /  125], loss: 0.179
[Epoch: 8, Batch:   60 /  125], loss: 0.223
[Epoch: 8, Batch:   70 /  125], loss: 0.237
[Epoch: 8, Batch:   80 /  125], loss: 0.237
[Epoch: 8, Batch:   90 /  125], loss: 0.216
[Epoch: 8, Batch:  100 /  125], loss: 0.201
[Epoch: 8, Batch:  110 /  125], loss: 0.237
[Epoch: 8, Batch:  120 /  125], loss: 0.228
Valid accuracy: 88 %
[Epoch: 9, Batch:   10 /  125], loss: 0.200
[Epoch: 9, Batch:   20 /  125], loss: 0.202
[Epoch: 9, Batch:   30 /  125], loss: 0.243
[Epoch: 9, Batch:   40 /  125], loss: 0.211
[Epoch: 9, Batch:   50 /  125], loss: 0.162
[Epoch: 9, Batch:   60 /  125], loss: 0.294
[Epoch: 9, Batch:   70 /  125], loss: 0.287
[Epoch: 9, Batch:   80 /  125], loss: 0.242
[Epoch: 9, Batch:   90 /  125], loss: 0.293
[Epoch: 9, Batch:  100 /  125], loss: 0.172
[Epoch: 9, Batch:  110 /  125], loss: 0.192
[Epoch: 9, Batch:  120 /  125], loss: 0.242
Valid accuracy: 88 %
[Epoch: 10, Batch:   10 /  125], loss: 0.203
[Epoch: 10, Batch:   20 /  125], loss: 0.315
[Epoch: 10, Batch:   30 /  125], loss: 0.209
[Epoch: 10, Batch:   40 /  125], loss: 0.238
[Epoch: 10, Batch:   50 /  125], loss: 0.143
[Epoch: 10, Batch:   60 /  125], loss: 0.206
[Epoch: 10, Batch:   70 /  125], loss: 0.186
[Epoch: 10, Batch:   80 /  125], loss: 0.242
[Epoch: 10, Batch:   90 /  125], loss: 0.211
[Epoch: 10, Batch:  100 /  125], loss: 0.284
[Epoch: 10, Batch:  110 /  125], loss: 0.209
[Epoch: 10, Batch:  120 /  125], loss: 0.184
Valid accuracy: 87 %
[Epoch: 11, Batch:   10 /  125], loss: 0.230
[Epoch: 11, Batch:   20 /  125], loss: 0.221
[Epoch: 11, Batch:   30 /  125], loss: 0.235
[Epoch: 11, Batch:   40 /  125], loss: 0.153
[Epoch: 11, Batch:   50 /  125], loss: 0.216
[Epoch: 11, Batch:   60 /  125], loss: 0.236
[Epoch: 11, Batch:   70 /  125], loss: 0.210
[Epoch: 11, Batch:   80 /  125], loss: 0.226
[Epoch: 11, Batch:   90 /  125], loss: 0.230
[Epoch: 11, Batch:  100 /  125], loss: 0.283
[Epoch: 11, Batch:  110 /  125], loss: 0.259
[Epoch: 11, Batch:  120 /  125], loss: 0.156
Valid accuracy: 87 %
[Epoch: 12, Batch:   10 /  125], loss: 0.193
[Epoch: 12, Batch:   20 /  125], loss: 0.199
[Epoch: 12, Batch:   30 /  125], loss: 0.199
[Epoch: 12, Batch:   40 /  125], loss: 0.274
[Epoch: 12, Batch:   50 /  125], loss: 0.148
[Epoch: 12, Batch:   60 /  125], loss: 0.189
[Epoch: 12, Batch:   70 /  125], loss: 0.223
[Epoch: 12, Batch:   80 /  125], loss: 0.187
[Epoch: 12, Batch:   90 /  125], loss: 0.220
[Epoch: 12, Batch:  100 /  125], loss: 0.204
[Epoch: 12, Batch:  110 /  125], loss: 0.232
[Epoch: 12, Batch:  120 /  125], loss: 0.210
Valid accuracy: 89 %
[Epoch: 13, Batch:   10 /  125], loss: 0.215
[Epoch: 13, Batch:   20 /  125], loss: 0.167
[Epoch: 13, Batch:   30 /  125], loss: 0.203
[Epoch: 13, Batch:   40 /  125], loss: 0.212
[Epoch: 13, Batch:   50 /  125], loss: 0.248
[Epoch: 13, Batch:   60 /  125], loss: 0.225
[Epoch: 13, Batch:   70 /  125], loss: 0.229
[Epoch: 13, Batch:   80 /  125], loss: 0.227
[Epoch: 13, Batch:   90 /  125], loss: 0.206
[Epoch: 13, Batch:  100 /  125], loss: 0.228
[Epoch: 13, Batch:  110 /  125], loss: 0.193
[Epoch: 13, Batch:  120 /  125], loss: 0.204
Valid accuracy: 88 %
[Epoch: 14, Batch:   10 /  125], loss: 0.215
[Epoch: 14, Batch:   20 /  125], loss: 0.213
[Epoch: 14, Batch:   30 /  125], loss: 0.229
[Epoch: 14, Batch:   40 /  125], loss: 0.233
[Epoch: 14, Batch:   50 /  125], loss: 0.198
[Epoch: 14, Batch:   60 /  125], loss: 0.204
[Epoch: 14, Batch:   70 /  125], loss: 0.205
[Epoch: 14, Batch:   80 /  125], loss: 0.219
[Epoch: 14, Batch:   90 /  125], loss: 0.174
[Epoch: 14, Batch:  100 /  125], loss: 0.201
[Epoch: 14, Batch:  110 /  125], loss: 0.224
[Epoch: 14, Batch:  120 /  125], loss: 0.165
Valid accuracy: 88 %
[Epoch: 15, Batch:   10 /  125], loss: 0.242
[Epoch: 15, Batch:   20 /  125], loss: 0.240
[Epoch: 15, Batch:   30 /  125], loss: 0.196
[Epoch: 15, Batch:   40 /  125], loss: 0.216
[Epoch: 15, Batch:   50 /  125], loss: 0.223
[Epoch: 15, Batch:   60 /  125], loss: 0.187
[Epoch: 15, Batch:   70 /  125], loss: 0.175
[Epoch: 15, Batch:   80 /  125], loss: 0.213
[Epoch: 15, Batch:   90 /  125], loss: 0.235
[Epoch: 15, Batch:  100 /  125], loss: 0.259
[Epoch: 15, Batch:  110 /  125], loss: 0.188
[Epoch: 15, Batch:  120 /  125], loss: 0.145
Valid accuracy: 89 %
[Epoch: 16, Batch:   10 /  125], loss: 0.179
[Epoch: 16, Batch:   20 /  125], loss: 0.182
[Epoch: 16, Batch:   30 /  125], loss: 0.160
[Epoch: 16, Batch:   40 /  125], loss: 0.255
[Epoch: 16, Batch:   50 /  125], loss: 0.141
[Epoch: 16, Batch:   60 /  125], loss: 0.220
[Epoch: 16, Batch:   70 /  125], loss: 0.156
[Epoch: 16, Batch:   80 /  125], loss: 0.206
[Epoch: 16, Batch:   90 /  125], loss: 0.242
[Epoch: 16, Batch:  100 /  125], loss: 0.241
[Epoch: 16, Batch:  110 /  125], loss: 0.261
[Epoch: 16, Batch:  120 /  125], loss: 0.172
Valid accuracy: 87 %
[Epoch: 17, Batch:   10 /  125], loss: 0.216
[Epoch: 17, Batch:   20 /  125], loss: 0.191
[Epoch: 17, Batch:   30 /  125], loss: 0.192
[Epoch: 17, Batch:   40 /  125], loss: 0.148
[Epoch: 17, Batch:   50 /  125], loss: 0.293
[Epoch: 17, Batch:   60 /  125], loss: 0.237
[Epoch: 17, Batch:   70 /  125], loss: 0.243
[Epoch: 17, Batch:   80 /  125], loss: 0.180
[Epoch: 17, Batch:   90 /  125], loss: 0.175
[Epoch: 17, Batch:  100 /  125], loss: 0.195
[Epoch: 17, Batch:  110 /  125], loss: 0.246
[Epoch: 17, Batch:  120 /  125], loss: 0.185
Valid accuracy: 87 %
[Epoch: 18, Batch:   10 /  125], loss: 0.187
[Epoch: 18, Batch:   20 /  125], loss: 0.231
[Epoch: 18, Batch:   30 /  125], loss: 0.281
[Epoch: 18, Batch:   40 /  125], loss: 0.189
[Epoch: 18, Batch:   50 /  125], loss: 0.268
[Epoch: 18, Batch:   60 /  125], loss: 0.248
[Epoch: 18, Batch:   70 /  125], loss: 0.168
[Epoch: 18, Batch:   80 /  125], loss: 0.180
[Epoch: 18, Batch:   90 /  125], loss: 0.233
[Epoch: 18, Batch:  100 /  125], loss: 0.261
[Epoch: 18, Batch:  110 /  125], loss: 0.208
[Epoch: 18, Batch:  120 /  125], loss: 0.155
Valid accuracy: 89 %
[Epoch: 19, Batch:   10 /  125], loss: 0.196
[Epoch: 19, Batch:   20 /  125], loss: 0.245
[Epoch: 19, Batch:   30 /  125], loss: 0.198
[Epoch: 19, Batch:   40 /  125], loss: 0.170
[Epoch: 19, Batch:   50 /  125], loss: 0.164
[Epoch: 19, Batch:   60 /  125], loss: 0.233
[Epoch: 19, Batch:   70 /  125], loss: 0.229
[Epoch: 19, Batch:   80 /  125], loss: 0.201
[Epoch: 19, Batch:   90 /  125], loss: 0.233
[Epoch: 19, Batch:  100 /  125], loss: 0.232
[Epoch: 19, Batch:  110 /  125], loss: 0.254
[Epoch: 19, Batch:  120 /  125], loss: 0.240
Valid accuracy: 87 %
[Epoch: 20, Batch:   10 /  125], loss: 0.181
[Epoch: 20, Batch:   20 /  125], loss: 0.215
[Epoch: 20, Batch:   30 /  125], loss: 0.209
[Epoch: 20, Batch:   40 /  125], loss: 0.229
[Epoch: 20, Batch:   50 /  125], loss: 0.209
[Epoch: 20, Batch:   60 /  125], loss: 0.263
[Epoch: 20, Batch:   70 /  125], loss: 0.228
[Epoch: 20, Batch:   80 /  125], loss: 0.151
[Epoch: 20, Batch:   90 /  125], loss: 0.190
[Epoch: 20, Batch:  100 /  125], loss: 0.205
[Epoch: 20, Batch:  110 /  125], loss: 0.146
[Epoch: 20, Batch:  120 /  125], loss: 0.190
Valid accuracy: 88 %
[Epoch: 21, Batch:   10 /  125], loss: 0.207
[Epoch: 21, Batch:   20 /  125], loss: 0.237
[Epoch: 21, Batch:   30 /  125], loss: 0.165
[Epoch: 21, Batch:   40 /  125], loss: 0.153
[Epoch: 21, Batch:   50 /  125], loss: 0.255
[Epoch: 21, Batch:   60 /  125], loss: 0.259
[Epoch: 21, Batch:   70 /  125], loss: 0.142
[Epoch: 21, Batch:   80 /  125], loss: 0.225
[Epoch: 21, Batch:   90 /  125], loss: 0.223
[Epoch: 21, Batch:  100 /  125], loss: 0.213
[Epoch: 21, Batch:  110 /  125], loss: 0.177
[Epoch: 21, Batch:  120 /  125], loss: 0.161
Valid accuracy: 88 %
[Epoch: 22, Batch:   10 /  125], loss: 0.245
[Epoch: 22, Batch:   20 /  125], loss: 0.163
[Epoch: 22, Batch:   30 /  125], loss: 0.153
[Epoch: 22, Batch:   40 /  125], loss: 0.201
[Epoch: 22, Batch:   50 /  125], loss: 0.257
[Epoch: 22, Batch:   60 /  125], loss: 0.201
[Epoch: 22, Batch:   70 /  125], loss: 0.200
[Epoch: 22, Batch:   80 /  125], loss: 0.170
[Epoch: 22, Batch:   90 /  125], loss: 0.225
[Epoch: 22, Batch:  100 /  125], loss: 0.176
[Epoch: 22, Batch:  110 /  125], loss: 0.160
[Epoch: 22, Batch:  120 /  125], loss: 0.188
Valid accuracy: 89 %
Epoch    22: reducing learning rate of group 0 to 1.0000e-04.
[Epoch: 23, Batch:   10 /  125], loss: 0.202
[Epoch: 23, Batch:   20 /  125], loss: 0.161
[Epoch: 23, Batch:   30 /  125], loss: 0.182
[Epoch: 23, Batch:   40 /  125], loss: 0.277
[Epoch: 23, Batch:   50 /  125], loss: 0.180
[Epoch: 23, Batch:   60 /  125], loss: 0.237
[Epoch: 23, Batch:   70 /  125], loss: 0.181
[Epoch: 23, Batch:   80 /  125], loss: 0.222
[Epoch: 23, Batch:   90 /  125], loss: 0.169
[Epoch: 23, Batch:  100 /  125], loss: 0.237
[Epoch: 23, Batch:  110 /  125], loss: 0.169
[Epoch: 23, Batch:  120 /  125], loss: 0.201
Valid accuracy: 88 %
[Epoch: 24, Batch:   10 /  125], loss: 0.207
[Epoch: 24, Batch:   20 /  125], loss: 0.194
[Epoch: 24, Batch:   30 /  125], loss: 0.197
[Epoch: 24, Batch:   40 /  125], loss: 0.208
[Epoch: 24, Batch:   50 /  125], loss: 0.201
[Epoch: 24, Batch:   60 /  125], loss: 0.208
[Epoch: 24, Batch:   70 /  125], loss: 0.190
[Epoch: 24, Batch:   80 /  125], loss: 0.199
[Epoch: 24, Batch:   90 /  125], loss: 0.290
[Epoch: 24, Batch:  100 /  125], loss: 0.165
[Epoch: 24, Batch:  110 /  125], loss: 0.172
[Epoch: 24, Batch:  120 /  125], loss: 0.197
Valid accuracy: 88 %
[Epoch: 25, Batch:   10 /  125], loss: 0.149
[Epoch: 25, Batch:   20 /  125], loss: 0.145
[Epoch: 25, Batch:   30 /  125], loss: 0.207
[Epoch: 25, Batch:   40 /  125], loss: 0.214
[Epoch: 25, Batch:   50 /  125], loss: 0.210
[Epoch: 25, Batch:   60 /  125], loss: 0.213
[Epoch: 25, Batch:   70 /  125], loss: 0.265
[Epoch: 25, Batch:   80 /  125], loss: 0.246
[Epoch: 25, Batch:   90 /  125], loss: 0.261
[Epoch: 25, Batch:  100 /  125], loss: 0.172
[Epoch: 25, Batch:  110 /  125], loss: 0.243
[Epoch: 25, Batch:  120 /  125], loss: 0.222
Valid accuracy: 88 %
[Epoch: 26, Batch:   10 /  125], loss: 0.209
[Epoch: 26, Batch:   20 /  125], loss: 0.190
[Epoch: 26, Batch:   30 /  125], loss: 0.242
[Epoch: 26, Batch:   40 /  125], loss: 0.228
[Epoch: 26, Batch:   50 /  125], loss: 0.212
[Epoch: 26, Batch:   60 /  125], loss: 0.214
[Epoch: 26, Batch:   70 /  125], loss: 0.179
[Epoch: 26, Batch:   80 /  125], loss: 0.191
[Epoch: 26, Batch:   90 /  125], loss: 0.199
[Epoch: 26, Batch:  100 /  125], loss: 0.166
[Epoch: 26, Batch:  110 /  125], loss: 0.224
[Epoch: 26, Batch:  120 /  125], loss: 0.160
Valid accuracy: 88 %
Epoch    26: reducing learning rate of group 0 to 1.0000e-05.
[Epoch: 27, Batch:   10 /  125], loss: 0.198
[Epoch: 27, Batch:   20 /  125], loss: 0.174
[Epoch: 27, Batch:   30 /  125], loss: 0.198
[Epoch: 27, Batch:   40 /  125], loss: 0.187
[Epoch: 27, Batch:   50 /  125], loss: 0.194
[Epoch: 27, Batch:   60 /  125], loss: 0.180
[Epoch: 27, Batch:   70 /  125], loss: 0.180
[Epoch: 27, Batch:   80 /  125], loss: 0.195
[Epoch: 27, Batch:   90 /  125], loss: 0.207
[Epoch: 27, Batch:  100 /  125], loss: 0.203
[Epoch: 27, Batch:  110 /  125], loss: 0.267
[Epoch: 27, Batch:  120 /  125], loss: 0.299
Valid accuracy: 87 %
[Epoch: 28, Batch:   10 /  125], loss: 0.215
[Epoch: 28, Batch:   20 /  125], loss: 0.180
[Epoch: 28, Batch:   30 /  125], loss: 0.237
[Epoch: 28, Batch:   40 /  125], loss: 0.186
[Epoch: 28, Batch:   50 /  125], loss: 0.247
[Epoch: 28, Batch:   60 /  125], loss: 0.246
[Epoch: 28, Batch:   70 /  125], loss: 0.208
[Epoch: 28, Batch:   80 /  125], loss: 0.259
[Epoch: 28, Batch:   90 /  125], loss: 0.189
[Epoch: 28, Batch:  100 /  125], loss: 0.198
[Epoch: 28, Batch:  110 /  125], loss: 0.178
[Epoch: 28, Batch:  120 /  125], loss: 0.161
Valid accuracy: 89 %
[Epoch: 29, Batch:   10 /  125], loss: 0.180
[Epoch: 29, Batch:   20 /  125], loss: 0.196
[Epoch: 29, Batch:   30 /  125], loss: 0.182
[Epoch: 29, Batch:   40 /  125], loss: 0.228
[Epoch: 29, Batch:   50 /  125], loss: 0.239
[Epoch: 29, Batch:   60 /  125], loss: 0.176
[Epoch: 29, Batch:   70 /  125], loss: 0.184
[Epoch: 29, Batch:   80 /  125], loss: 0.182
[Epoch: 29, Batch:   90 /  125], loss: 0.230
[Epoch: 29, Batch:  100 /  125], loss: 0.215
[Epoch: 29, Batch:  110 /  125], loss: 0.170
[Epoch: 29, Batch:  120 /  125], loss: 0.268
Valid accuracy: 89 %
[Epoch: 30, Batch:   10 /  125], loss: 0.210
[Epoch: 30, Batch:   20 /  125], loss: 0.165
[Epoch: 30, Batch:   30 /  125], loss: 0.214
[Epoch: 30, Batch:   40 /  125], loss: 0.235
[Epoch: 30, Batch:   50 /  125], loss: 0.139
[Epoch: 30, Batch:   60 /  125], loss: 0.279
[Epoch: 30, Batch:   70 /  125], loss: 0.189
[Epoch: 30, Batch:   80 /  125], loss: 0.190
[Epoch: 30, Batch:   90 /  125], loss: 0.168
[Epoch: 30, Batch:  100 /  125], loss: 0.226
[Epoch: 30, Batch:  110 /  125], loss: 0.159
[Epoch: 30, Batch:  120 /  125], loss: 0.158
Valid accuracy: 88 %
Epoch    30: reducing learning rate of group 0 to 1.0000e-06.

Process finished with exit code 0
